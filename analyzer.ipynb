{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a83dda55",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTANCE_THRESHOLD=100\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "def sample_analyze(logs, benchmark_helper, save_path, model_name,\n",
    "                   is_picture=False, sample_ids=None):  \n",
    "    \"\"\"\n",
    "    Compute per-sample accuracy & average distance for a single model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    logs : dict\n",
    "        Parsed *_log.json* of one model, keyed by sample_id.\n",
    "    benchmark_helper : MapGuesserBenchmark\n",
    "        Helper providing golden labels & distance calculation.\n",
    "    save_path : str | Path\n",
    "        Root directory for results; a sub-folder named <model_name> will be created.\n",
    "    model_name : str\n",
    "        Short name of the model, used for sub-folder & plot titles.\n",
    "    is_picture : bool, default False\n",
    "        If True draw and show histogram plots.\n",
    "    sample_ids : list[str] | None\n",
    "        If given, analyse only these samples.\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Columns: sample_id, accuracy, avg_distance_km\n",
    "    \"\"\"\n",
    "    golden_labels = benchmark_helper.load_golden_labels()\n",
    "    sample2accu, sample2distance = {}, {}\n",
    "\n",
    "    # ---------------- main loop ----------------\n",
    "    for sample in golden_labels:\n",
    "        if sample_ids and sample[\"id\"] not in sample_ids:   # <-- filter\n",
    "            continue\n",
    "        hits = 0                     # correct predictions counter\n",
    "        dist_sum = 0.0               # accumulated distance\n",
    "        cnt = 0                      # total valid predictions\n",
    "\n",
    "        log = logs[sample[\"id\"]]\n",
    "        gt  = {\"lat\": sample[\"lat\"], \"lng\": sample[\"lng\"]}\n",
    "\n",
    "        for run in log:\n",
    "            for pred in run[\"predictions\"]:\n",
    "                # filter out invalid / empty placeholder predictions\n",
    "                if isinstance(pred, dict) and \"lat\" in pred and \"lon\" in pred \\\n",
    "                        and not (pred[\"lat\"] == 0.0 and pred[\"lon\"] == 0.0):\n",
    "                    dist = benchmark_helper.calculate_distance(gt, (pred[\"lat\"], pred[\"lon\"]))\n",
    "                    dist_sum += dist\n",
    "                    if dist <= DISTANCE_THRESHOLD:\n",
    "                        hits += 1\n",
    "                    cnt += 1\n",
    "\n",
    "        # ---------- safe division: avoid division by zero ----------\n",
    "        if cnt:\n",
    "            sample2accu[sample[\"id\"]]     = hits / cnt\n",
    "            sample2distance[sample[\"id\"]] = dist_sum / cnt\n",
    "        else:\n",
    "            print(f\"[Warning] sample {sample['id']} has no valid predictions\")\n",
    "            sample2accu[sample[\"id\"]]     = None\n",
    "            sample2distance[sample[\"id\"]] = None\n",
    "    # -------------------------------------------\n",
    "\n",
    "    save_path = Path(save_path) / model_name\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"sample_id\": list(sample2accu.keys()),\n",
    "        \"accuracy\":         [sample2accu[k]     for k in sample2accu],\n",
    "        \"avg_distance_km\":  [sample2distance[k] for k in sample2distance],\n",
    "    })\n",
    "    df.to_json(save_path / \"sample_analyze.json\", indent=2)\n",
    "\n",
    "    if is_picture:\n",
    "        # draw two histograms (accuracy / average distance)\n",
    "        plt.figure(figsize=(14,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        sns.histplot(df[\"accuracy\"], bins=20, color=\"#4C72B0\")\n",
    "        plt.title(f\"{model_name} – Per-sample Accuracy Distribution\")\n",
    "        plt.xlabel(\"Accuracy\"); plt.ylabel(\"Count\")\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        sns.histplot(df[\"avg_distance_km\"], bins=20, color=\"#55A868\")\n",
    "        plt.title(f\"{model_name} – Per-sample Average Distance Distribution\")\n",
    "        plt.xlabel(\"Average Distance (km)\"); plt.ylabel(\"Count\")\n",
    "\n",
    "        plt.tight_layout(); plt.show()\n",
    "    return df\n",
    "\n",
    "def step_analyze(logs, benchmark_helper, save_path, model_name, steps,\n",
    "                 is_picture=False, sample_ids=None, is_specific_sample=False,\n",
    "                 sample_id=None, save_picture=False, picture_save_path=None):\n",
    "    \"\"\"\n",
    "    Aggregate accuracy & average distance *per step* for one model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    logs : dict\n",
    "        Parsed *_log.json* of one model.\n",
    "    benchmark_helper : MapGuesserBenchmark\n",
    "        Helper object.\n",
    "    save_path : str | Path\n",
    "        Base directory to store JSON & plots; a <model_name> sub-folder will\n",
    "        be created automatically.\n",
    "    model_name : str\n",
    "        Name of the model to be used in file names / titles.\n",
    "    steps : int\n",
    "        Max number of steps contained in the log files.\n",
    "    is_picture : bool, default False\n",
    "        Whether to display plots immediately.\n",
    "    sample_ids : list[str] | None\n",
    "        If given, analyse only these samples.\n",
    "    is_specific_sample : bool, default False\n",
    "        If True only analyse the specified sample_id.\n",
    "    sample_id : str | None\n",
    "        The sample id to analyse when `is_specific_sample` is True.\n",
    "    save_picture : bool, default False\n",
    "        Whether to save plots to `picture_save_path`.\n",
    "    picture_save_path : str | Path | None\n",
    "        Target path when `save_picture` is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Columns: step, accuracy, avg_distance_km\n",
    "    \"\"\"\n",
    "    golden_labels = benchmark_helper.load_golden_labels()\n",
    "    step_hits         = [0]   * steps   # correct predictions per step\n",
    "    step_dist_sum     = [0.0] * steps   # distance accumulation per step\n",
    "    step_pred_cnt     = [0]   * steps   # total predictions per step\n",
    "\n",
    "    # ---------------- iterate logs ----------------\n",
    "    for sample in golden_labels:\n",
    "        if is_specific_sample and sample[\"id\"] != sample_id:\n",
    "            continue\n",
    "        if sample_ids and sample[\"id\"] not in sample_ids:   \n",
    "            continue\n",
    "        log = logs[sample[\"id\"]]\n",
    "        gt  = {\"lat\": sample[\"lat\"], \"lng\": sample[\"lng\"]}\n",
    "\n",
    "        for run in log:\n",
    "            for idx, pred in enumerate(run[\"predictions\"]):\n",
    "                if idx >= steps:\n",
    "                    break  # defensive: log steps exceed configured steps\n",
    "                if isinstance(pred, dict) and \"lat\" in pred and \"lon\" in pred \\\n",
    "                        and not (pred[\"lat\"] == 0.0 and pred[\"lon\"] == 0.0):\n",
    "                    dist   = benchmark_helper.calculate_distance(gt, (pred[\"lat\"], pred[\"lon\"]))\n",
    "                    step_dist_sum [idx] += dist\n",
    "                    if dist <= DISTANCE_THRESHOLD:\n",
    "                        step_hits[idx] += 1\n",
    "                    step_pred_cnt[idx] += 1\n",
    "    # ----------------------------------------------\n",
    "\n",
    "    # ---------- calculate metrics, avoid division by zero ----------\n",
    "    step_accuracy = [\n",
    "        (step_hits[i] / step_pred_cnt[i]) if step_pred_cnt[i] else None\n",
    "        for i in range(steps)\n",
    "    ]\n",
    "    step_avg_dist = [\n",
    "        (step_dist_sum[i] / step_pred_cnt[i]) if step_pred_cnt[i] else None\n",
    "        for i in range(steps)\n",
    "    ]\n",
    "\n",
    "    df_step = pd.DataFrame({\n",
    "        \"step\":            list(range(1, steps+1)),\n",
    "        \"accuracy\":        step_accuracy,\n",
    "        \"avg_distance_km\": step_avg_dist,\n",
    "    })\n",
    "\n",
    "    # save JSON results\n",
    "    save_path = Path(save_path) / model_name\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    df_step.to_json(save_path / f\"{model_name}_step_summary.json\",\n",
    "                    orient=\"records\", indent=2)\n",
    "\n",
    "    # ---------- optional plotting ----------\n",
    "    if is_picture:\n",
    "        plt.figure(figsize=(12,5))\n",
    "        sns.lineplot(x=\"step\", y=\"accuracy\", data=df_step, marker=\"o\", color=\"#4C72B0\")\n",
    "        plt.ylim(0,1); plt.xlabel(\"Step #\"); plt.ylabel(\"Accuracy\")\n",
    "        title_suffix = f\" – {sample_id}\" if is_specific_sample else \"\"\n",
    "        plt.title(f\"{model_name}{title_suffix} – Accuracy vs Step\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        if save_picture and picture_save_path:\n",
    "            plt.savefig(picture_save_path.replace('.png', '_accuracy.png'),\n",
    "                        dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(12,5))\n",
    "        sns.lineplot(x=\"step\", y=\"avg_distance_km\", data=df_step,\n",
    "                     marker=\"o\", color=\"#55A868\")\n",
    "        plt.xlabel(\"Step #\"); plt.ylabel(\"Average Distance (km)\")\n",
    "        plt.title(f\"{model_name}{title_suffix} – Average Distance vs Step\")\n",
    "        plt.grid(True, alpha=0.3); plt.tight_layout()\n",
    "        if save_picture and picture_save_path:\n",
    "            plt.savefig(picture_save_path.replace('.png', '_distance.png'),\n",
    "                        dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    return df_step\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6d3ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_combined_results(log_paths, benchmark_helper,\n",
    "                          save_path: str,\n",
    "                          steps: int = 20,\n",
    "                          show: bool = True,\n",
    "                          sample_ids: list[str] | None = None):   # NEW param\n",
    "    \"\"\"\n",
    "    Read multiple *_log.json files, run sample/step analyze,\n",
    "    then draw combined accuracy & distance plots.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    log_paths : list[str]\n",
    "        Each path points to a *_log.json produced by main.py.\n",
    "    benchmark_helper : MapGuesserBenchmark\n",
    "        Helper with distance / label utilities.\n",
    "    save_path : str\n",
    "        Directory to write individual sample/step json & plots.\n",
    "    steps : int, default 20\n",
    "        Max step count contained in those logs.\n",
    "    show : bool, default True\n",
    "        Whether to call plt.show(); set False when running in batch jobs.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    sample_dfs, step_dfs = {}, {}\n",
    "\n",
    "    for log_path in log_paths:\n",
    "        with open(log_path, \"r\") as f:\n",
    "            logs = json.load(f)\n",
    "\n",
    "        model_name = os.path.basename(log_path).split('_')[0]\n",
    "        sample_df = sample_analyze(\n",
    "            logs, benchmark_helper, save_path, model_name,\n",
    "            is_picture=False, sample_ids=sample_ids           \n",
    "        )\n",
    "        step_df   = step_analyze(\n",
    "            logs, benchmark_helper, save_path, model_name, steps,\n",
    "            is_picture=False, sample_ids=sample_ids\n",
    "        )\n",
    "\n",
    "        sample_dfs[model_name] = sample_df\n",
    "        step_dfs  [model_name] = step_df\n",
    "\n",
    "    # ---------- draw combined step curves ----------\n",
    "    combined_step = pd.concat(\n",
    "        [df.assign(model=name) for name, df in step_dfs.items()],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    plt.figure(figsize=(12,5))\n",
    "    sns.lineplot(data=combined_step, x=\"step\", y=\"accuracy\",\n",
    "                 hue=\"model\", marker=\"o\")\n",
    "    plt.ylim(0,1); plt.xlabel(\"Step #\"); plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy vs Step – All Models\");  plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    if show: plt.show()\n",
    "    plt.savefig(Path(save_path)/\"accuracy_vs_step.png\")\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    sns.lineplot(data=combined_step, x=\"step\", y=\"avg_distance_km\",\n",
    "                 hue=\"model\", marker=\"o\")\n",
    "    plt.xlabel(\"Step #\"); plt.ylabel(\"Avg Distance (km)\")\n",
    "    plt.title(\"Avg Distance vs Step – All Models\"); plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    if show: plt.show()\n",
    "    plt.savefig(Path(save_path)/\"distance_vs_step.png\")\n",
    "    \n",
    "\n",
    "    # ---------- draw combined sample hist ----------\n",
    "    combined_sample = pd.concat(\n",
    "        [df.assign(model=name) for name, df in sample_dfs.items()],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    plt.figure(figsize=(14,5))\n",
    "    sns.histplot(data=combined_sample, x=\"accuracy\",\n",
    "                 hue=\"model\", bins=20, alpha=0.5)\n",
    "    plt.title(\"Per-sample Accuracy Distribution – All Models\")\n",
    "    plt.xlabel(\"Accuracy\"); plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    if show: plt.show()\n",
    "    plt.savefig(Path(save_path)/\"Per-sample Accuracy Distribution – All Models\")\n",
    "    \n",
    "    plt.figure(figsize=(14,5))\n",
    "    sns.histplot(data=combined_sample, x=\"avg_distance_km\",\n",
    "                 hue=\"model\", bins=20, alpha=0.5)\n",
    "    plt.title(\"Per-sample Avg Distance Distribution – All Models\")\n",
    "    plt.xlabel(\"Avg Distance (km)\"); plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    if show: plt.show()\n",
    "    plt.savefig(Path(save_path)/\"Per-sample Avg Distance Distribution – All Models.png\")\n",
    "\n",
    "    return combined_sample, combined_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b82dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark import MapGuesserBenchmark\n",
    "log_paths=[\"./results/test/20250809_010023/gemini-1.5-pro_log.json\",\n",
    "           \"./results/test/20250809_010023/gemini-2.5-pro_log.json\",\n",
    "           \"./results/test/20250810_212246/gemini-2.0-flash_log.json\",\n",
    "           \"./results/test/20250811_143758/gpt-4o/gpt-4o_log.json\",\n",
    "           \"./results/test/20250811_143758/gpt-4o-mini/gpt-4o-mini_log.json\",\n",
    "           \"./results/test/20250811_143758/qwen-vl-max/qwen-vl-max_log.json\",\n",
    "           ]\n",
    "save_path=\"/home/Omniscient/results/test/pictures/\"\n",
    "benchmark_helper = MapGuesserBenchmark(dataset_name=\"test\")\n",
    "plot_combined_results(log_paths,benchmark_helper,save_path,steps=10,show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec7ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from benchmark import MapGuesserBenchmark\n",
    "benchmark_helper = MapGuesserBenchmark(dataset_name=\"test\")\n",
    "golden_labels=benchmark_helper.load_golden_labels()\n",
    "log_paths=[\"/home/Omniscient/results/test/20250809_010023/gemini-1.5-pro_log.json\",\n",
    "           \"/home/Omniscient/results/test/20250809_010023/gemini-2.5-pro_log.json\",\n",
    "           ]\n",
    "save_path=\"/home/Omniscient/results/test/20250809_010023/\"\n",
    "log_path=log_paths[1]\n",
    "with open(log_path, \"r\") as f:\n",
    "    logs = json.load(f)\n",
    "\n",
    "# oberserving model performance on specific sample\n",
    "model_name=log_path.split('/')[-1].split('_')[0]\n",
    "for sample in golden_labels:\n",
    "    step_res=step_analyze(logs,benchmark_helper,\n",
    "                        save_path,model_name,20,\n",
    "                        is_picture=True,\n",
    "                        is_specific_sample=True,\n",
    "                        sample_id=sample[\"id\"],\n",
    "                        save_picture=True,\n",
    "                        picture_save_path=f\"/home/Omniscient/results/test/sample_picture/{model_name}/{sample['id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853340d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-1.5-pro : 39 valid samples\n",
      "gemini-2.5-pro : 39 valid samples\n",
      "qwen-vl-max : 16 valid samples\n",
      "gpt-4o-mini : 19 valid samples\n",
      "gpt-4o : 19 valid samples\n",
      "gemini-2.0-flash : 26 valid samples\n",
      "\n",
      "========== GLOBAL ==========\n",
      "Valid (hit in ≥1 model)   : 43 samples\n",
      "Invalid (all models fail) : 7 samples\n",
      "\n",
      "Invalid sample IDs:\n",
      "['4acf7d7e-8309-4e57-88b2-1ea1019c1719', 'c4d4352f-6285-42c1-bbae-231ca95da48a', '09ce31a1-a719-4ed9-a344-7987214902c1', '9a6c5a97-8501-489d-bade-f07bbcbebeea', 'cbbab275-9be4-4d3a-b077-45ae1f8d14ff', '08ef293d-2894-489f-b77f-377115c75921', '1fc918f8-1b83-4aeb-a785-22a3cd15a407']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "base_dir = Path(\"/home/Omniscient/results/test/20250809_010023\")\n",
    "files = [\n",
    "    \"./results/test/20250809_010023/gemini-1.5-pro/sample_analyze.json\",\n",
    "    \"./results/test/20250809_010023/gemini-2.5-pro/sample_analyze.json\",\n",
    "    \"./results/test/pictures/qwen-vl-max/sample_analyze.json\",\n",
    "    \"./results/test/pictures/gpt-4o-mini/sample_analyze.json\",\n",
    "    \"./results/test/pictures/gpt-4o/sample_analyze.json\",\n",
    "    \"./results/test/pictures/gemini-2.0-flash/sample_analyze.json\",\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# pass-1: collect per-model + global accuracy info\n",
    "# ------------------------------------------------------------\n",
    "valid_ids_by_model = {}\n",
    "sample_acc_table   = defaultdict(list)   # sample_id -> [acc_model1, acc_model2, …]\n",
    "\n",
    "for fp in files:\n",
    "    with open(fp, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # the DataFrame was saved with orient=\"columns\" – each column is a dict\n",
    "    ids        = data[\"sample_id\"]        # dict: index -> sample_id\n",
    "    accuracies = data[\"accuracy\"]         # dict: index -> accuracy\n",
    "    model_name = Path(fp).parent.name\n",
    "\n",
    "    model_valid_ids = []\n",
    "    for idx, sample_id in ids.items():\n",
    "        acc = accuracies.get(idx)\n",
    "        sample_acc_table[sample_id].append(acc)\n",
    "\n",
    "        if acc and acc > 0:\n",
    "            model_valid_ids.append(sample_id)\n",
    "\n",
    "    valid_ids_by_model[model_name] = model_valid_ids\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# pass-2: global valid / invalid split\n",
    "# ------------------------------------------------------------\n",
    "valid_ids   = []   # at least one model accuracy > 0\n",
    "invalid_ids = []   # all models accuracy == 0 or None\n",
    "\n",
    "for sid, acc_list in sample_acc_table.items():\n",
    "    if any(acc and acc > 0 for acc in acc_list):\n",
    "        valid_ids.append(sid)\n",
    "    else:\n",
    "        invalid_ids.append(sid)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# output\n",
    "# ------------------------------------------------------------\n",
    "for model, ids in valid_ids_by_model.items():\n",
    "    print(f\"{model} : {len(ids)} valid samples\")\n",
    "\n",
    "print(\"\\n========== GLOBAL ==========\")\n",
    "print(f\"Valid (hit in ≥1 model)   : {len(valid_ids)} samples\")\n",
    "print(f\"Invalid (all models fail) : {len(invalid_ids)} samples\")\n",
    "print(\"\\nInvalid sample IDs:\")\n",
    "print(invalid_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25919f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ids=['d6250b7f-4da5-42c1-8c8d-0423e67e77be', '3bb51463-0a02-4ce4-9e61-6e0f28491897', '7a606d59-46f3-4522-b2be-2e5a5576e155', '262d348a-a60a-42d8-bd4f-68aafe98d1fb', '1929ea7c-af27-42d0-9931-66d5ad451d21', '7bc2a39e-ac61-4704-a950-203117b4aca2', 'a77120f7-f65b-4ea4-8419-4c2f599c2ed8', 'bf12b96e-5ee7-4815-bc1e-2ef6ccaf3b5c', '6a5589de-e1fb-46c4-96c3-85cfb161444e', '3f0e8c12-109e-4db7-a228-52a156ca880d', 'a76f6ed2-5bb0-4750-bfd0-5a01fa052772', 'a6f20438-972f-48b0-8dc6-e95baec1c8c2', '4ee65f3b-aeaa-49d1-abda-28e270cca142', '3933f509-49f4-413f-b32d-95398910b3b6', 'e32c0681-97bc-440e-9d8e-c1cb9511d47d', '15861215-f932-426b-a6fa-08ae0cd5ae54', '011c76d0-d1cf-40f0-b243-3593448bce84', 'a16553c1-8b4a-44f0-9d6d-9c23b1b93c86', '0246f9d3-be8d-40f0-805e-d0446ef2d183', '54375156-8b78-4e60-afc9-f1172deba69d', '4fa45765-4ce7-4adc-a4fb-7f54149d6f27', '8ff247f4-efdf-47e8-8aab-7752f7a7a033', '41aa250b-f476-4c47-a8b3-1b170f892039', '6186abe6-6343-41bd-b7c6-ef65e5fb5a83', 'f9d01601-da06-4286-b83f-aad48292ef56', '29521be4-0c47-40b4-9fe5-14dd37686eed', '0049770c-0e79-4f6e-a230-85815c5afca4', '108d3530-8cd1-4554-9e27-f4161c25b64f', '684589c2-db98-4fa0-a909-26677d622781', '9e52e1ef-b7c8-4290-a50c-dea42684329c', '54ccc34f-ae30-449b-83cf-3f6485186e38', '9903bb23-294e-44a2-9ecf-180808b82d67', '4381807b-d04c-4c04-8b93-78a588016cb7', 'c9d4d2c0-be12-4104-9fdf-3ffd7b9b539a', '574ac51d-1de1-46b2-9f90-5b1da1d79339', '87e095f0-467b-4539-978b-46eecfdf1efc', '3badb1cb-5ffb-4c07-812e-ee85646a4279', '1acb3834-1f22-4c0c-8cd3-b992e4546f88', '8dacb066-8fa4-4f03-87e3-34d86f5863fb']\n",
    "\n",
    "plot_combined_results(\n",
    "    log_paths,\n",
    "    benchmark_helper,\n",
    "    save_path=\"/home/Omniscient/results/test/filtered_pictures/\",\n",
    "    steps=10,\n",
    "    sample_ids=filtered_ids, \n",
    "    show=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
